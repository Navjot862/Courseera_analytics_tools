{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "APIs.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqyY-hd0EX9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "169aac13-e937-493d-e2e4-70643f2b6cbf"
      },
      "source": [
        "##Installing required librariries\r\n",
        "!pip install azure-cognitiveservices-language-textanalytics\r\n",
        "!pip install azure-ai-textanalytics --pre\r\n",
        "!pip install pandas\r\n",
        "!pip install transformers"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: azure-cognitiveservices-language-textanalytics in /usr/local/lib/python3.6/dist-packages (0.2.0)\n",
            "Requirement already satisfied: msrest>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from azure-cognitiveservices-language-textanalytics) (0.6.19)\n",
            "Requirement already satisfied: azure-common~=1.1 in /usr/local/lib/python3.6/dist-packages (from azure-cognitiveservices-language-textanalytics) (1.1.26)\n",
            "Requirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from msrest>=0.5.0->azure-cognitiveservices-language-textanalytics) (1.3.0)\n",
            "Requirement already satisfied: requests~=2.16 in /usr/local/lib/python3.6/dist-packages (from msrest>=0.5.0->azure-cognitiveservices-language-textanalytics) (2.23.0)\n",
            "Requirement already satisfied: isodate>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from msrest>=0.5.0->azure-cognitiveservices-language-textanalytics) (0.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from msrest>=0.5.0->azure-cognitiveservices-language-textanalytics) (2020.12.5)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.5.0->msrest>=0.5.0->azure-cognitiveservices-language-textanalytics) (3.1.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-language-textanalytics) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-language-textanalytics) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-language-textanalytics) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from isodate>=0.6.0->msrest>=0.5.0->azure-cognitiveservices-language-textanalytics) (1.15.0)\n",
            "Requirement already satisfied: azure-ai-textanalytics in /usr/local/lib/python3.6/dist-packages (5.1.0b4)\n",
            "Requirement already satisfied: azure-common~=1.1 in /usr/local/lib/python3.6/dist-packages (from azure-ai-textanalytics) (1.1.26)\n",
            "Requirement already satisfied: six>=1.6 in /usr/local/lib/python3.6/dist-packages (from azure-ai-textanalytics) (1.15.0)\n",
            "Requirement already satisfied: msrest>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from azure-ai-textanalytics) (0.6.19)\n",
            "Requirement already satisfied: azure-core<2.0.0,>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from azure-ai-textanalytics) (1.10.0)\n",
            "Requirement already satisfied: requests~=2.16 in /usr/local/lib/python3.6/dist-packages (from msrest>=0.6.0->azure-ai-textanalytics) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from msrest>=0.6.0->azure-ai-textanalytics) (1.3.0)\n",
            "Requirement already satisfied: isodate>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from msrest>=0.6.0->azure-ai-textanalytics) (0.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from msrest>=0.6.0->azure-ai-textanalytics) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests~=2.16->msrest>=0.6.0->azure-ai-textanalytics) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests~=2.16->msrest>=0.6.0->azure-ai-textanalytics) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests~=2.16->msrest>=0.6.0->azure-ai-textanalytics) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.0->azure-ai-textanalytics) (3.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/ea/634945faff8ad6984b98f7f3d98f6d83083a18af44e349744d90bde81f80/transformers-4.2.0-py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 14.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 51.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 39.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=dd820cbaad23c4e5800cc8d16db4a23602c65d53f337e38a66fbf7f70df2a780\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLyU2QqBfn2J",
        "outputId": "935efb66-ff01-4db3-f4f6-528b6f8cfdd4"
      },
      "source": [
        "##clone github code\r\n",
        "!git clone https://github.com/Navjot862/Courseera_analytics_tools"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Courseera_analytics_tools'...\n",
            "remote: Enumerating objects: 111, done.\u001b[K\n",
            "remote: Counting objects: 100% (111/111), done.\u001b[K\n",
            "remote: Compressing objects: 100% (110/110), done.\u001b[K\n",
            "remote: Total 111 (delta 52), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (111/111), 543.77 KiB | 2.16 MiB/s, done.\n",
            "Resolving deltas: 100% (52/52), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uN9iwn_EiebF"
      },
      "source": [
        "import pandas as pd\r\n",
        "from azure.ai.textanalytics import TextAnalyticsClient\r\n",
        "from azure.core.credentials import AzureKeyCredential\r\n",
        "from transformers import pipeline"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5AchVI7hraF"
      },
      "source": [
        "##Reading Data\r\n",
        "df=pd.read_csv(\"/content/Courseera_analytics_tools/d4.csv\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXcgbxKYDsUc"
      },
      "source": [
        "key = \"486d8e2ede2d413f8219a98bc6219cad\"\n",
        "endpoint = \"https://text65.cognitiveservices.azure.com/\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMbEpDPiR4qN"
      },
      "source": [
        "Client=TextAnalyticsClient(endpoint,AzureKeyCredential(key))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dg_g7HWjlZ5d"
      },
      "source": [
        "# documents=parsed\r\n",
        "l1=list(df['Review'])\r\n",
        "response = Client.analyze_sentiment(l1)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmGH1dEQaoiU"
      },
      "source": [
        "sentimentAnalysis = pipeline(\"sentiment-analysis\")\r\n",
        "op=sentimentAnalysis(l1)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocG_k5hiWXez"
      },
      "source": [
        "for i in range(len(l1)):\r\n",
        "  sentiment_api=response[i].sentiment\r\n",
        "  positive_score_api=response[i].confidence_scores.positive\r\n",
        "  negative_score_api=response[i].confidence_scores.negative\r\n",
        "  neutral_score_api=response[i].confidence_scores.neutral\r\n",
        "  ##\r\n",
        "  pipeline_sentiment=op[i]['label']\r\n",
        "  pipeline_score=op[i]['score']"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-azdv850BTLO"
      },
      "source": [
        "sentimentAnalysis = pipeline(\"sentiment-analysis\")\r\n",
        "op=sentimentAnalysis(l1)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9c5t9rBaBS5",
        "outputId": "8f357fcf-80a7-48a7-9a14-a7b566067e7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "op"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9998671412467957},\n",
              " {'label': 'POSITIVE', 'score': 0.9996583461761475},\n",
              " {'label': 'POSITIVE', 'score': 0.9966945052146912},\n",
              " {'label': 'NEGATIVE', 'score': 0.992240846157074},\n",
              " {'label': 'NEGATIVE', 'score': 0.9972217679023743},\n",
              " {'label': 'NEGATIVE', 'score': 0.9995130896568298},\n",
              " {'label': 'NEGATIVE', 'score': 0.9914065003395081},\n",
              " {'label': 'POSITIVE', 'score': 0.9269000291824341},\n",
              " {'label': 'POSITIVE', 'score': 0.6627724766731262},\n",
              " {'label': 'NEGATIVE', 'score': 0.9980362057685852}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EIy55qM-u9o"
      },
      "source": [
        "sentiment=op['sentiment']"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faIGWipt-1Va"
      },
      "source": [
        "confidence_score=op['confidence_scores']"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGqqVI39_Rlf",
        "outputId": "7780ea4e-bf62-4e15-bfba-38b490baabab"
      },
      "source": [
        "confidence_score"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentConfidenceScores(positive=0.99, neutral=0.01, negative=0.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGXtEuk2_duq",
        "outputId": "f2c136b7-0c4f-44eb-d75d-c2fcb939a7da"
      },
      "source": [
        "dict(confidence_score)['negative']\r\n",
        "dict(confidence_score)['positive']\r\n",
        "dict(confidence_score)['neutral']"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.01"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrB9D0pODsUe"
      },
      "source": [
        "def sentiment_analysis(client):\n",
        "\n",
        "    documents = parsed\n",
        "    for i in range(10):\n",
        "        response = client.analyze_sentiment(documents = documents)[i]\n",
        "        print(\"Document Sentiment: {}\".format(response.sentiment))\n",
        "        print(\"Overall scores: positive={0:.2f}; neutral={1:.2f}; negative={2:.2f} \\n\".format(\n",
        "            response.confidence_scores.positive,\n",
        "            response.confidence_scores.neutral,\n",
        "            response.confidence_scores.negative,\n",
        "        ))\n",
        "        for idx, sentence in enumerate(response.sentences):\n",
        "            print(\"Sentence: {}\".format(sentence.text))\n",
        "            print(\"Sentence {} sentiment: {}\".format(idx+1, sentence.sentiment))\n",
        "            print(\"Sentence score:\\nPositive={0:.2f}\\nNeutral={1:.2f}\\nNegative={2:.2f}\\n\".format(\n",
        "                sentence.confidence_scores.positive,\n",
        "                sentence.confidence_scores.neutral,\n",
        "                sentence.confidence_scores.negative,\n",
        "            ))\n",
        "          "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIQWmmdlj2dk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}